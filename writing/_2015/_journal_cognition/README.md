# TODO FOR WONKY MARBLES (manuscript)

p. 4 cite marcus/love for people who hate on Bayesians for being lax in their treatment of priors.
p. 5 brief phrase summarizing bayesian prior inference
p. 5 footnote 2 insert link to prior slider experiment
p. 6 figure 1: update graphs to reflect mh's numbers
p. 6 insert procedure on prior inference; discuss the results from the two different dependent measures and how we expect one to over-sample extremes and one to be too flat?
p. 8 insert participant payment amount
p. 10 fix barr et al reference
p. 10 rerun and rereport all analyses with mh's numbers
p. 11 describe concept of a lifted variable
p. 11 footnote describing other possible priors
p. 12 we need to explain where oddness comes from – maybe there’s an easy graphical way of showing how for items with different priors, a ‘some’ utterance is more or less wonky, by showing the marginal probabilities of observing each utterance for these different items?
p. 12 rerun and rereport all analyses with mh's numbers
p. 13 insert payment amount
p. 14 put in here somewhere the relation between wonkiness and the comprehension data: for all and none, while there are huge changes in wonkiness by prior, we don’t expect this to show up in the comprehension data because the semantics of the utterances restricts the interpretation to just one state, regardless of the prior. but for ”some”, which has a weak semantics, wonkiness shifts the overall interpretation in a way that compresses the effect of the prior
p. 15 To see this, XXX discuss effect of setting lambda to 0: random choice between between true utterances) put actual model predictions in a plot

p. 19 rerun and rereport all analyses with mh's numbers
p. 20 add some discussion of speaker reliability results
p. 20 GD overhaul



# TODO FOR WONKY MARBLES (COGSCI, and potential stuff to add to big manuscript)

- considerable research in the word and discourse comprehension literature
   has examined how the “standard” interpretation of a word or phrase
   (or even of the letters or phonemes in an individual word) can be
   dramatically altered by context.  Connecting with this literature could
   enhance the relevance and broad applicability of the results.
   

- is there a reason to report MSE results as opposed to R^2 results for
   the model/empirical data comparisons?  It would seem that the latter
   would be more intuitive than MSE and convey the same points.      
      
- it's a
   very interesting empirical question how prior world knowledge as well as
   rich information from the physical and linguistic contexts can enter in
   to pragmatic inferences and language comprehension in general. For
   example, there is a great deal of evidence from the sentence processing
   literature that people take a great deal of such information into account
   when understanding language.
   
- What additional predictions (perhaps in
   other pragmatic domains) could this model make?


generally: think more about slider measure (see especially reviewer 3's comments, who actually went to the trouble of doing the experiment)